{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import Accelerator\n",
    "from torch import nn\n",
    "\n",
    "from models import BatteryGPT\n",
    "from data_provider.data_factory import data_provider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = time.strftime('%Y%m%d%H%M', time.localtime())\n",
    "parser = argparse.ArgumentParser(description='Time-LLM')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=False, default='long_term_forecast',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--is_training', type=int, required=False, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=False, default='Battery', help='model id')\n",
    "parser.add_argument('--model_comment', type=str, required=False, default='none', help='prefix when saving test results')\n",
    "parser.add_argument('--model', type=str, required=False, default='BatteryGPTv0',\n",
    "                    help='model name, options: [Autoformer, DLinear]')\n",
    "parser.add_argument('--seed', type=int, default=42, help='random seed')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=False, default='mbatdata', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./dataset/my', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='trimmed_LX3_ss0_se100_cr05_C_V_T_vs_CE.csv', help='data file')\n",
    "parser.add_argument('--drop_bid', type=int, default=0)\n",
    "parser.add_argument('--cutting_rate', type=float, default=1.2)\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; '\n",
    "                            'M:multivariate predict multivariate, S: univariate predict univariate, '\n",
    "                            'MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--loader', type=str, default='modal', help='dataset type')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, '\n",
    "                            'options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], '\n",
    "                            'you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./cache/', help='location of model checkpoints')\n",
    "parser.add_argument('--logger', type=str, default='./logs', help='log folder')\n",
    "parser.add_argument('--on_server', type=bool, default=False)\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_limit', type=int, default=48, help='raw sequence length')\n",
    "parser.add_argument('--seq_len', type=int, default=18, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=9, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=30, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--enc_in', type=int, default=11, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=1, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=16, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=32, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')\n",
    "parser.add_argument('--patch_len', type=int, default=8, help='patch length')\n",
    "parser.add_argument('--stride', type=int, default=4, help='stride')\n",
    "parser.add_argument('--prompt_domain', type=int, default=0, help='')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=1, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--align_epochs', type=int, default=10, help='alignment epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=8, help='batch size of train input data')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=8, help='batch size of model evaluation')\n",
    "parser.add_argument('--patience', type=int, default=10, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='MSE', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--pct_start', type=float, default=0.2, help='pct_start')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "parser.add_argument('--llm_layers', type=int, default=6)\n",
    "parser.add_argument('--percent', type=int, default=100)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "accelerator = Accelerator(mixed_precision='bf16', device_placement=False)\n",
    "\n",
    "# 还原训练参数\n",
    "args.llm_layers = 32\n",
    "args.d_model = 32\n",
    "args.d_ff = 128\n",
    "args.enc_in = 11\n",
    "args.dec_in = 7\n",
    "args.c_out = 1\n",
    "\n",
    "args.batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-2 load completed: (27471,)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "# train_data, train_loader = data_provider(args, 'train')\n",
    "# vali_data, vali_loader = data_provider(args, 'val')\n",
    "test_data, test_loader = data_provider(args, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "sd_202403142139 = r'./cache\\long_term_forecast_Battery_BatteryGPT_masked_battery_ftM_sl18_ll9_pl30_dm32_nh8_el2_dl1_df128_fc1_ebtimeF_Exp_0-BatteryGPT-Masked_battery\\checkpoint'\n",
    "sd_202403151801 = r'cache\\long_term_forecast_Battery_BatteryGPT_masked_battery_ftM_sl18_ll9_pl30_dm32_nh8_el2_dl1_df128_fc1_ebtimeF_Exp_0-BatteryGPT-Masked_battery\\202403151801_checkpoint'\n",
    "model = BatteryGPT.Model(args).float()\n",
    "model.load_state_dict(torch.load(sd_202403151801))\n",
    "\n",
    "test_loader, model = accelerator.prepare(\n",
    "    test_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318867546"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型参数量\n",
    "cnts = 0\n",
    "for param in model.parameters():\n",
    "    cnts += param.numel()\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "batch 1\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 425.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m dec_inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(batch_y[:, \u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mpred_len:, :])\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     18\u001b[0m dec_inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([batch_y[:, :args\u001b[39m.\u001b[39mlabel_len, :], dec_inp], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[39m=\u001b[39m model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n\u001b[0;32m     21\u001b[0m f_dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mfeatures \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMS\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     22\u001b[0m outputs \u001b[39m=\u001b[39m outputs[:, \u001b[39m-\u001b[39margs\u001b[39m.\u001b[39mpred_len:, f_dim:]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\accelerate\\utils\\operations.py:817\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 817\u001b[0m     \u001b[39mreturn\u001b[39;00m model_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\accelerate\\utils\\operations.py:805\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_to_fp32(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\amp\\autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_autocast\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     15\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 16\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\OneDrive\\大论文\\code\\BatteryGPT\\Time-LLM-main\\models\\BatteryGPT.py:110\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_enc, x_mark_enc, x_dec, x_mark_dec, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlong_term_forecast\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mshort_term_forecast\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 110\u001b[0m         dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n\u001b[0;32m    111\u001b[0m         \u001b[39mreturn\u001b[39;00m dec_out[:, \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_len:, :]\n\u001b[0;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\OneDrive\\大论文\\code\\BatteryGPT\\Time-LLM-main\\models\\BatteryGPT.py:162\u001b[0m, in \u001b[0;36mModel.forecast\u001b[1;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39m# 数据和prompt一起进入骨干网络训练\u001b[39;00m\n\u001b[0;32m    161\u001b[0m llama_enc_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([prompt_embeddings, enc_out], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllama(inputs_embeds\u001b[39m=\u001b[39;49mllama_enc_out)\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m    163\u001b[0m dec_out \u001b[39m=\u001b[39m dec_out[:, :, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_ff]\n\u001b[0;32m    164\u001b[0m dec_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m    165\u001b[0m     dec_out, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_vars, dec_out\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], dec_out\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    876\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    877\u001b[0m         block\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    878\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    885\u001b[0m         output_attentions,\n\u001b[0;32m    886\u001b[0m     )\n\u001b[0;32m    887\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    889\u001b[0m         hidden_states,\n\u001b[0;32m    890\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    891\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    892\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    893\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    894\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    895\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    896\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    897\u001b[0m     )\n\u001b[0;32m    899\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    900\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:427\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    425\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    426\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 427\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[0;32m    428\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[0;32m    429\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:355\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[39m.\u001b[39mFloatTensor]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[0;32m    354\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m--> 355\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(hidden_states)\n\u001b[0;32m    356\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(hidden_states)\n\u001b[0;32m    357\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\torch_py39\\lib\\site-packages\\transformers\\activations.py:57\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0.5\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39minput\u001b[39;49m \u001b[39m*\u001b[39;49m (\u001b[39m1.0\u001b[39;49m \u001b[39m+\u001b[39;49m torch\u001b[39m.\u001b[39;49mtanh(math\u001b[39m.\u001b[39;49msqrt(\u001b[39m2.0\u001b[39;49m \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49mpi) \u001b[39m*\u001b[39;49m (\u001b[39minput\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m0.044715\u001b[39;49m \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49mpow(\u001b[39minput\u001b[39;49m, \u001b[39m3.0\u001b[39;49m))))\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 425.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 验证模型\n",
    "model.to(accelerator.device)\n",
    "criterion = nn.MSELoss()\n",
    "mae_metric = nn.L1Loss()\n",
    "\n",
    "y = []\n",
    "yhat = []\n",
    "model.eval()\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "    print('batch %d' %i)\n",
    "    batch_x = batch_x.float().to(accelerator.device)\n",
    "    batch_y = batch_y.float().to(accelerator.device)\n",
    "    batch_x_mark = batch_x_mark.float().to(accelerator.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(accelerator.device)\n",
    "\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float()\n",
    "\n",
    "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    f_dim = -1 if args.features == 'MS' else 0\n",
    "    outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "    batch_y = batch_y[:, -args.pred_len:, f_dim:]\n",
    "\n",
    "    pred = outputs.detach().cpu().numpy()\n",
    "    true = batch_y.detach().cpu().numpy()\n",
    "\n",
    "    # loss = criterion(pred, true)\n",
    "    # mae_loss = mae_metric(pred, true)\n",
    "\n",
    "    y.append(true)\n",
    "    yhat.append(pred)\n",
    "    \n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 30, 1)\n",
      "(1, 1, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array(y)\n",
    "yhat1 = np.array(yhat)\n",
    "\n",
    "print(y1.shape)\n",
    "print(yhat1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch</th>\n",
       "      <th>seq</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.534874</td>\n",
       "      <td>-0.558594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.509245</td>\n",
       "      <td>-0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.483616</td>\n",
       "      <td>-0.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.457986</td>\n",
       "      <td>-0.472656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.432770</td>\n",
       "      <td>-0.447266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.407141</td>\n",
       "      <td>-0.419922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.381512</td>\n",
       "      <td>-0.386719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.355882</td>\n",
       "      <td>-0.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.330253</td>\n",
       "      <td>-0.330078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.304624</td>\n",
       "      <td>-0.302734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.278994</td>\n",
       "      <td>-0.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.253365</td>\n",
       "      <td>-0.244141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.227735</td>\n",
       "      <td>-0.215820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.202106</td>\n",
       "      <td>-0.188477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.176477</td>\n",
       "      <td>-0.159180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.150434</td>\n",
       "      <td>-0.131836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.124805</td>\n",
       "      <td>-0.105469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.099175</td>\n",
       "      <td>-0.075684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.073133</td>\n",
       "      <td>-0.049561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.047503</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.021461</td>\n",
       "      <td>0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.026001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.048584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.056254</td>\n",
       "      <td>0.073242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.082297</td>\n",
       "      <td>0.094238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.108340</td>\n",
       "      <td>0.116699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.134796</td>\n",
       "      <td>0.133789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.160839</td>\n",
       "      <td>0.153320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.187708</td>\n",
       "      <td>0.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.188121</td>\n",
       "      <td>0.185547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y      yhat\n",
       "batch seq id                    \n",
       "0     0   0  -0.534874 -0.558594\n",
       "          1  -0.509245 -0.531250\n",
       "          2  -0.483616 -0.503906\n",
       "          3  -0.457986 -0.472656\n",
       "          4  -0.432770 -0.447266\n",
       "          5  -0.407141 -0.419922\n",
       "          6  -0.381512 -0.386719\n",
       "          7  -0.355882 -0.359375\n",
       "          8  -0.330253 -0.330078\n",
       "          9  -0.304624 -0.302734\n",
       "          10 -0.278994 -0.273438\n",
       "          11 -0.253365 -0.244141\n",
       "          12 -0.227735 -0.215820\n",
       "          13 -0.202106 -0.188477\n",
       "          14 -0.176477 -0.159180\n",
       "          15 -0.150434 -0.131836\n",
       "          16 -0.124805 -0.105469\n",
       "          17 -0.099175 -0.075684\n",
       "          18 -0.073133 -0.049561\n",
       "          19 -0.047503 -0.023438\n",
       "          20 -0.021461  0.001144\n",
       "          21  0.004582  0.026001\n",
       "          22  0.030212  0.048584\n",
       "          23  0.056254  0.073242\n",
       "          24  0.082297  0.094238\n",
       "          25  0.108340  0.116699\n",
       "          26  0.134796  0.133789\n",
       "          27  0.160839  0.153320\n",
       "          28  0.187708  0.171875\n",
       "          29  0.188121  0.185547"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = np.array(y).squeeze(-1)\n",
    "yhat1 = np.array(yhat).squeeze(-1)\n",
    "\n",
    "# print(y1.shape)\n",
    "# print(yhat1.shape)\n",
    "\n",
    "# 将前两个维度作为 MultiIndex\n",
    "index = pd.MultiIndex.from_product([range(s) for s in y1.shape[:3]], names=['batch', 'seq', 'id'])\n",
    "# 将数组转换为 DataFrame\n",
    "df1 = pd.DataFrame(y1.reshape(-1), index=index, columns=['y'])\n",
    "# 将前两个维度作为 MultiIndex\n",
    "index = pd.MultiIndex.from_product([range(s) for s in yhat1.shape[:3]], names=['batch', 'seq', 'id'])\n",
    "# 将数组转换为 DataFrame\n",
    "df2 = pd.DataFrame(yhat1.reshape(-1), index=index, columns=['yhat'])\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "display(df)\n",
    "\n",
    "# df.to_csv('./ana_model_pred.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  0, 0),\n",
       "            (  1, 0),\n",
       "            (  2, 0),\n",
       "            (  3, 0),\n",
       "            (  4, 0),\n",
       "            (  5, 0),\n",
       "            (  6, 0),\n",
       "            (  7, 0),\n",
       "            (  8, 0),\n",
       "            (  9, 0),\n",
       "            ...\n",
       "            (159, 0),\n",
       "            (160, 0),\n",
       "            (161, 0),\n",
       "            (162, 0),\n",
       "            (163, 0),\n",
       "            (164, 0),\n",
       "            (165, 0),\n",
       "            (166, 0),\n",
       "            (167, 0),\n",
       "            (168, 0)],\n",
       "           names=['batch', 'seq'], length=169)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ana_model_pred.csv')\n",
    "df = df.set_index(['batch', 'seq'])\n",
    "df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[(0,0), ['y', 'yhat']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[i for i in range(5)] for j in [i for i in range(5)]]\n",
    "print(a)\n",
    "isinstance(np.average(a, axis=None), list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a01226d361f198896d49db63f7116ec40e89b3ed34592777616e15f2f06b1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
